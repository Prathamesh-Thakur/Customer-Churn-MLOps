# ğŸ“¡ Customer Churn MLOps Platform

A production-grade machine learning operations system for predicting customer churn in telecommunications. This project demonstrates a complete MLOps pipeline with automated model training, drift monitoring, predictions serving, and interactive UIâ€”all orchestrated with Apache Airflow and containerized with Docker.

---

## ğŸ—ï¸ Tech Stack

### Core ML & Data Processing
- **Python 3.13.7** - Core language
- **scikit-learn 1.8.0** - Machine learning (RandomForestClassifier)
- **pandas 2.3.3** - Data manipulation and analysis
- **joblib** - Model serialization and persistence
- **KaggleHub 1.0.0** - Data persistence

### Web & API Services
- **FastAPI 0.129.0** - High-performance REST API for predictions
- **Uvicorn 0.41.0** - ASGI server
- **Pydantic 2.12.5** - Data validation
- **Streamlit 1.54.0** - Interactive web UI
- **Requests** - HTTP client for API communication

### Orchestration & Scheduling
- **Apache Airflow 2.7.2** - Workflow orchestration
- **PostgreSQL 13** - Database backend for Airflow

### DevOps & Containerization
- **Docker** - Container images
- **Docker Compose** - Multi-container orchestration

---

## ğŸ“ Directory Structure

```
Customer-Churn-MLOps/
â”œâ”€â”€ ğŸ“„ README.md                         # This file
â”œâ”€â”€ ğŸ“„ Dockerfile                        # Container image definition
â”œâ”€â”€ ğŸ“„ docker-compose.yaml               # Multi-service orchestration
â”œâ”€â”€ ğŸ“„ requirements.txt                  # Python dependencies
â”‚
â”œâ”€â”€ ğŸ“‚ src/                              # Core ML/Data Pipeline
â”‚   â”œâ”€â”€ train.py                         # Model training script
â”‚   â”œâ”€â”€ predict.py                       # Inference engine (prediction logic)
â”‚   â”œâ”€â”€ monitor.py                       # Data drift detection (PSI scores)
â”‚   â”œâ”€â”€ data_gen.py                      # Synthetic data generation
â”‚   â””â”€â”€ imp_features.py                  # Feature importance calculation
â”‚
â”œâ”€â”€ ğŸ“‚ api/                              # FastAPI Prediction Server
â”‚   â””â”€â”€ app.py                           # REST API endpoints
â”‚
â”œâ”€â”€ ğŸ“‚ ui/                               # Streamlit Frontend
â”‚   â””â”€â”€ app.py                           # Interactive web interface
â”‚
â”œâ”€â”€ ğŸ“‚ airflow/                          # Airflow Orchestration
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ drift_dag.py                 # Daily monitoring & retraining pipeline
â”‚
â”œâ”€â”€ ğŸ“‚ models/                           # Trained ML Artifacts
â”‚   â”œâ”€â”€ training_model.joblib            # Trained Random Forest classifier
â”‚   â”œâ”€â”€ encoder.joblib                   # Feature encoder
â”‚   â”œâ”€â”€ imp_features.txt                 # List of important features
â”‚   â”œâ”€â”€ PSI_scores.txt                   # Data drift detection scores
â”‚   â””â”€â”€ validation_probabilities.npy     # Cached validation predictions
â”‚
â””â”€â”€ ğŸ“‚ data/                             # Data Storage
    â”œâ”€â”€ live_inference_logs.csv          # Prediction logs & ground truth
    â””â”€â”€ batches/
        â”œâ”€â”€ batch_0_training.csv         # Training dataset
        â”œâ”€â”€ batch_1_production.csv       # Production batch data
        â””â”€â”€ batch_2_production.csv       # Additional production batch
```

---

## ğŸ›ï¸ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       CUSTOMER CHURN MLOPS PLATFORM                     â”‚
â”‚                        (Docker Compose Network)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          JSON         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¨ UI       â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  ğŸ“¡ API      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit   â”‚    Prediction &       â”‚  FastAPI     â”‚          â”‚
â”‚  (Port 8501) â”‚    Customer Data      â”‚  (Port 8000) â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
                                              â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               Appends Data â”‚                  â”‚
â”‚ ğŸ“… ORCHESTRATORâ”‚                            â–¼                  â”‚
â”‚ Apache Airflow â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ (Port 8080)    â”‚ â”‚ ğŸ“Š MONITORING    â”‚â—„â”€â”€â”€â”¤  ğŸ“Š DATA LOGS   â”‚   â”‚ HTTP POST
â”‚                â”œâ–ºâ”‚ monitor.py       â”‚    â”‚ live_inference_ â”‚   â”‚ /reload
â”‚ â€¢ DAG triggers â”‚ â”‚                  â”‚    â”‚  logs.csv       â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â”‚                   â”‚                                    â”‚
        â”‚                   â”‚ If drift > 0.2                     â”‚
        â”‚                   â–¼                                    â”‚
        â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚          â”‚ ğŸ‹ï¸ TRAINING      â”‚    â”‚ ğŸ“¦ MODEL ARTIFACTSâ”‚ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ train.py         â”œâ”€â”€â”€â–ºâ”‚ model.joblib      â”œâ”€â”¤ Loads
                   â”‚                  â”‚Saveâ”‚ features.txt      â”‚ â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                            â”‚                                    â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### System Components

| Component | Purpose | Technology | Port |
|-----------|---------|-----------|------|
| **Airflow Webserver** | Orchestration & monitoring UI | Apache Airflow | 8080 |
| **Airflow Scheduler** | Executes DAG tasks automatically | Apache Airflow | - |
| **FastAPI** | Prediction API server | FastAPI + Uvicorn | 8000 |
| **Streamlit** | Interactive web dashboard | Streamlit | 8501 |
| **PostgreSQL** | Stores Airflow metadata | PostgreSQL | 5432 |

### Data Flow

1. **Training:** Load Telco customer dataset â†’ Extract important features â†’ Train RandomForest model â†’ Save artifacts
2. **Monitoring:** Periodically check for data drift using PSI (Population Stability Index) scores
3. **Inference:** Process customer input â†’ Encode features â†’ Run prediction â†’ Log results
4. **Auto-Retraining:** If drift detected â†’ Retrain model automatically via Airflow

---

## ğŸš€ How to Run Locally

### Prerequisites

Ensure you have installed:
- **Docker** (v20.10+)
- **Docker Compose** (v2.0+)
- **Git**

### Quick Start

1. **Clone the repository:**
   ```bash
   git clone <your-repo-url>
   cd Customer-Churn-MLOps
   ```

2. **Start all services with Docker Compose:**
   ```bash
   docker-compose up -d
   ```

   This will start:
   - PostgreSQL database
   - Apache Airflow (webserver + scheduler)
   - FastAPI prediction server
   - Streamlit UI

3. **Access the services:**

   | Service | URL | Credentials |
   |---------|-----|-------------|
   | **Airflow UI** | http://localhost:8080 | `airflow` / `airflow` |
   | **FastAPI Docs** | http://localhost:8000/docs | N/A |
   | **Streamlit UI** | http://localhost:8501 | N/A |

### Detailed Setup Steps

#### 1ï¸âƒ£ Build Docker Images
```bash
docker-compose build
```

#### 2ï¸âƒ£ Initialize Airflow Database
```bash
docker-compose run airflow-init
```
Wait 30 seconds for PostgreSQL to be ready first.

#### 3ï¸âƒ£ Start Services
```bash
docker-compose up -d
```

#### 4ï¸âƒ£ Verify Services are Running
```bash
docker-compose ps
```

You should see all containers in "Up" state:
- `postgres` - Database
- `airflow-webserver` - Airflow UI
- `airflow-scheduler` - Task scheduler
- `fastapi` - API server
- `streamlit` - Web UI

#### 5ï¸âƒ£ Check Logs (if issues)
```bash
# Airflow logs
docker-compose logs airflow-scheduler

# FastAPI logs
docker-compose logs fastapi

# Streamlit logs
docker-compose logs streamlit
```

#### 6ï¸âƒ£ Train Model (One-time Setup)
First, train the model to generate artifacts:
```bash
docker-compose exec fastapi python src/train.py
```

#### 7ï¸âƒ£ Trigger Airflow DAG
1. Open http://localhost:8080
2. Login with `airflow` / `airflow`
3. Find `daily_churn_retraining_pipeline` DAG
4. Click "Trigger DAG" button
5. Monitor execution in the UI

---

## ğŸ“‹ Usage Examples

### Make Predictions via API

**Using cURL:**
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "tenure": 24,
    "Contract": "One year",
    "MonthlyCharges": 65.5,
    "TotalCharges": 1572.0,
    "InternetService": "Fiber optic",
    "PaymentMethod": "Electronic check"
  }'
```

**Response:**
```json
{
  "churn_probability": 0.73,
  "prediction": 1,
  "status": "Prediction logged successfully"
}
```

### Use Streamlit UI
1. Navigate to http://localhost:8501
2. Adjust customer parameters with sliders and dropdowns
3. Click "Predict Churn" button
4. View probability and recommendation

### Monitor Drift & Retraining
1. Go to Airflow UI (http://localhost:8080)
2. Monitor `daily_churn_retraining_pipeline` DAG runs
3. Check PSI scores in `models/PSI_scores.txt`
4. View prediction logs in `data/live_inference_logs.csv`

---

## ğŸ”§ Development & Customization

### Running Individual Services Locally (without Docker)

**1. Setup Python Virtual Environment:**
```bash
python -m venv venv
source venv/Scripts/activate  # Windows
# source venv/bin/activate   # macOS/Linux
pip install -r requirements.txt
```

**2. Train Model:**
```bash
python src/train.py
```

**3. Start FastAPI Server:**
```bash
uvicorn api.app:app --host 0.0.0.0 --port 8000 --reload
```

**4. Start Streamlit App (in another terminal):**
```bash
streamlit run ui/app.py
```

### Modifying the Pipeline

- **Add features:** Edit `src/imp_features.py`
- **Change model:** Modify classifier in `src/train.py`
- **Adjust drift threshold:** Update PSI calculation in `src/monitor.py`
- **Schedule changes:** Edit `airflow/dags/drift_dag.py` schedule_interval

### Model Retraining

The model **automatically retrains daily** if drift is detected. To manually retrain:
```bash
docker-compose exec fastapi python src/train.py
```

---

## ğŸ“Š Key Metrics & Monitoring

### PSI (Population Stability Index)
Detects data drift between training and production batches. Higher PSI = more drift.

### Prediction Logs
Stored in `data/live_inference_logs.csv`:
- Customer features
- Churn probability
- Timestamp
- Ground truth (when available for model improvement)

### Airflow DAG Runs
Track in Airflow UI at http://localhost:8080

---

## ğŸ›‘ Troubleshooting

| Issue | Solution |
|-------|----------|
| **Port 8080 already in use** | Change in docker-compose.yaml: `"8081:8080"` |
| **PostgreSQL connection refused** | Wait 30s for DB to start, then run `docker-compose restart` |
| **Models not found error** | Run `docker-compose exec fastapi python src/train.py` |
| **API returns 500 error** | Check logs: `docker-compose logs fastapi` |
| **Streamlit can't connect to API** | Ensure FastAPI service is running: `docker-compose ps` |

---

## ğŸ“ˆ Production Deployment

For production:
1. Use environment variables for secrets (API keys, DB credentials)
2. Configure proper monitoring & logging (Prometheus, ELK stack)
3. Set up CI/CD pipeline (GitHub Actions, GitLab CI)
4. Use Kubernetes for orchestration instead of Docker Compose
5. Implement model versioning & rollback strategy
6. Add authentication/authorization to APIs
7. Monitor model performance metrics continuously

---

## ğŸ“ License

This project is licensed under the MIT License. See the LICENSE file for details.

---

## ğŸ“§ Contact & Support

For questions or issues, refer to the project documentation or create an issue in the repository.

---

**Last Updated:** February 21, 2026
